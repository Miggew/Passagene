# EmbryoScore v2 â€” Plano Completo de ImplementaÃ§Ã£o

## Documento Ãšnico de ReferÃªncia para Claude Code

**Projeto:** PassaGene â€” MÃ³dulo EmbryoScore  
**Data:** 13/02/2026  
**VersÃ£o:** 2.1 (cross-species transfer learning + scoring dual KNN+MLP)  
**Lab:** Passatempo EmbriÃµes, Dores do IndaiÃ¡/MG  
**Objetivo:** Substituir avaliaÃ§Ã£o Gemini (alucina) por DINOv2 + KNN + MLP cross-species (similaridade visual + cinÃ©tica real + classificador treinado).  
**PrincÃ­pio:** Alterar o mÃ­nimo possÃ­vel. Reaproveitar tudo que funciona.  
**Design System:** PassaGene DS â€” ver seÃ§Ã£o 18 para tokens obrigatÃ³rios.  
**InovaÃ§Ã£o:** Transfer learning cross-species usando ~2.800 referÃªncias pÃºblicas (humanas + bovinas) para bootstrap do atlas + classificador MLP desde o dia 1.

---

## 1. CONTEXTO E MOTIVAÃ‡ÃƒO

### 1.1 O que Ã© o EmbryoScore

Sistema de segunda opiniÃ£o automatizada para classificaÃ§Ã£o de embriÃµes bovinos (FIV). O biÃ³logo classifica manualmente e a IA oferece uma segunda opiniÃ£o baseada em similaridade visual + anÃ¡lise de atividade cinÃ©tica intracelular.

### 1.2 Por que substituir o sistema anterior

O sistema v1 usava Gemini Flash para avaliar morfologia de embriÃµes via prompt. **Resultado: todas as avaliaÃ§Ãµes estavam erradas.** O Gemini Flash (e modelos genÃ©ricos em geral) nÃ£o possuem conhecimento real de embriologia bovina e alucinam avaliaÃ§Ãµes convincentes porÃ©m incorretas.

### 1.3 Nova abordagem

Em vez de pedir a uma IA genÃ©rica para "avaliar", o novo sistema:

1. **Compara visualmente** o embriÃ£o com um banco de referÃªncias classificadas por biÃ³logos reais
2. **Analisa atividade cinÃ©tica** (movimento intracelular) via diferenÃ§a de pixels entre frames
3. **Combina ambos** numa imagem composta que o DINOv2 transforma em vetor
4. **Busca os 10 embriÃµes mais parecidos** (visual + cinÃ©tica) no banco por similaridade natural
5. **Vota** pela classificaÃ§Ã£o mais frequente entre os vizinhos
6. **Classificador MLP** treinado em dados cross-species (humano + bovino) fornece segunda opiniÃ£o
7. **Scoring dual** combina KNN + MLP com peso dinÃ¢mico (MLP domina no inÃ­cio, KNN assume conforme atlas cresce)

**Nenhuma IA generativa avalia. Ã‰ busca por similaridade + classificador treinado.**

**InovaÃ§Ã£o cross-species:** O atlas nasce com ~2.800 referÃªncias de datasets pÃºblicos (2.344 blastocistos humanos + 482 bovinos). A morfologia embrionÃ¡ria Ã© conservada entre mamÃ­feros â€” ICM, TE, blastocoel, fragmentaÃ§Ã£o sÃ£o visualmente idÃªnticos. O DINOv2 captura estrutura visual, nÃ£o espÃ©cie. Dados reais bovinos gradualmente substituem as referÃªncias cross-species conforme acumulam.

---

## 2. DIAGNÃ“STICO DO SISTEMA ATUAL

### O que funciona (NÃƒO MEXER)

| Componente | Arquivo | Status |
|---|---|---|
| CÃ¢mera + gravaÃ§Ã£o | `src/components/camera/EmbryoCamera.jsx` | âœ… Perfeito |
| Upload de vÃ­deo | `src/hooks/useEmbryoVideoUpload.ts` | âœ… Perfeito |
| Storage (Supabase) | Bucket `embryo-videos/` | âœ… Perfeito |
| Fila de anÃ¡lise | Tabela `embryo_analysis_queue` | âœ… Reaproveitar |
| Disparo fire-and-forget | `LotesFIV.tsx` linhas ~420-461 | âœ… Perfeito |
| Edge Function (estrutura) | `supabase/functions/embryo-analyze/index.ts` | âš ï¸ Manter estrutura, trocar conteÃºdo |
| DetecÃ§Ã£o de embriÃµes (Gemini box_2d) | Dentro da Edge Function, passo 5c | âœ… Perfeito |
| UI - pÃ¡gina de lotes | `src/pages/LotesFIV.tsx` | âœ… Manter |
| UI - botÃ£o de upload | `src/components/embryoscore/VideoUploadButton.tsx` | âœ… Manter |
| UI - detalhe do lote | `src/components/lotes/LoteDetailView.tsx` | âœ… Manter |

### O que NÃƒO funciona (SUBSTITUIR)

| Componente | Problema | SoluÃ§Ã£o |
|---|---|---|
| Cloud Run `/extract-frame` | Extrai 1 frame sÃ³ | Novo endpoint `/extract-and-crop` |
| Cloud Run `/analyze-activity` | CinÃ©tica de 1 frame (sem sentido) | **Remover. CinÃ©tica real no DINOv2 service** |
| Gemini avaliaÃ§Ã£o morfolÃ³gica (passo 5f) | **Alucina todas as avaliaÃ§Ãµes** | **Remover. Substituir por DINOv2 + KNN** |
| `embryo_scores` (campos) | Campos do resultado Gemini | Campos do resultado KNN |
| `EmbryoScoreCard.tsx` | Mostra dados do Gemini | Mostrar dados do KNN + mapa cinÃ©tico |
| `LoteScoreDashboard.tsx` | MÃ©dias do Gemini | DistribuiÃ§Ã£o por classe + concordÃ¢ncia |

---

## 3. ARQUITETURA â€” FLUXO CORRIGIDO

### REGRA CRÃTICA: Os 40 frames NUNCA saem do Cloud Run

A Edge Function do Supabase nÃ£o tem Canvas, ImageMagick, nem memÃ³ria suficiente pra manipular 40 frames completos. Todo processamento de imagem pesado fica no Cloud Run. **O celular nÃ£o processa nada.** SÃ³ grava, envia e exibe resultados.

```
EDGE FUNCTION (orquestra, leve):
  â”‚
  â”œâ”€ 1. Busca job, status â†’ processing
  â”‚
  â”œâ”€ 2. Cloud Run /extract-frame (JÃ EXISTE)
  â”‚     â†’ Retorna: 1 frame JPEG (base64)
  â”‚
  â”œâ”€ 3. Gemini box_2d no frame (JÃ EXISTE)
  â”‚     â†’ Retorna: bboxes[] dos embriÃµes detectados
  â”‚
  â”œâ”€ 4. Cloud Run /extract-and-crop (NOVO)
  â”‚     Recebe: video_url + bboxes
  â”‚     Internamente:
  â”‚       - Extrai 40 frames do vÃ­deo
  â”‚       - Aplica cada bbox nos 40 frames â†’ crops por embriÃ£o
  â”‚       - Frames completos MORREM aqui, nunca trafegam
  â”‚     Retorna: { embryo_0: [crop1...crop40], embryo_1: [...] }
  â”‚              (crops pequenos ~30KB cada)
  â”‚              + plate_frame_b64 (frame completo da placa, 1 sÃ³)
  â”‚
  â”œâ”€ 5. Cloud Run DINOv2 /analyze-embryo (NOVO, com GPU)
  â”‚     Para cada embriÃ£o (em PARALELO com Promise.all):
  â”‚       Recebe: 40 crops do embriÃ£o
  â”‚       Internamente:
  â”‚         - Alinha crops (template matching)
  â”‚         - Seleciona mais nÃ­tido (Laplacian)
  â”‚         - Calcula mapa cinÃ©tico (diff pixels + subtraÃ§Ã£o ruÃ­do)
  â”‚         - CompÃµe imagem (morph + mapa lado a lado)
  â”‚         - Gera embedding DINOv2 (768 dims)
  â”‚       Retorna: embedding + imagens + mÃ©tricas cinÃ©ticas
  â”‚
  â”œâ”€ 6. Supabase pgvector KNN (em PARALELO com Promise.all)
  â”‚     Para cada embriÃ£o:
  â”‚       match_embryos(embedding, 10) â†’ vizinhos â†’ votos
  â”‚
  â”œâ”€ 7. Salva imagens no Storage
  â”‚     plate_frame.jpg (1 por despacho)
  â”‚     emb_N_frame.jpg, emb_N_motion.jpg, emb_N_composite.jpg
  â”‚
  â”œâ”€ 8. Salva scores em embryo_scores + plate info na queue
  â”‚
  â””â”€ 9. Status â†’ completed

DEPOIS (revisÃ£o do relatÃ³rio â€” biÃ³logo NÃƒO classifica durante envase):
  BiÃ³logo abre tela de revisÃ£o prÃ©-despacho
  VÃª placa panorÃ¢mica com embriÃµes numerados (topo)
  Revisa cada embriÃ£o: frame + mapa + minimapa + sugestÃ£o KNN
  Confirma/corrige classificaÃ§Ã£o
  Cada confirmaÃ§Ã£o â†’ nova referÃªncia no atlas (cresce automaticamente)
  Quando todos classificados â†’ despacha
```

### ServiÃ§os e responsabilidades

| ServiÃ§o | Recebe | Retorna | Dados pesados |
|---|---|---|---|
| Edge Function | IDs e URLs | Orquestra chamadas | **Nunca toca em frames completos** |
| Cloud Run `/extract-frame` | video_url | 1 JPEG base64 | 1 frame |
| Cloud Run `/extract-and-crop` (NOVO) | video_url + bboxes | crops por embriÃ£o + plate_frame | **40 frames internos, morrem aqui** |
| Cloud Run DINOv2 `/analyze-embryo` (NOVO) | crops de 1 embriÃ£o | embedding + imagens | Crops pequenos (~30KB cada) |
| Supabase pgvector | embedding 768d | 10 vizinhos | Vetores (3KB) |

---

## 4. BANCO DE DADOS (Supabase)

### 4a. Habilitar pgvector

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

### 4b. Nova tabela: embryo_references

Esta tabela Ã© o "atlas" que cresce com o uso. Cada embriÃ£o classificado pelo biÃ³logo vira uma referÃªncia.

```sql
CREATE TABLE embryo_references (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  created_at TIMESTAMPTZ DEFAULT now(),
  
  -- IdentificaÃ§Ã£o
  lab_id UUID NOT NULL,
  lote_fiv_id UUID REFERENCES lotes_fiv(id),
  acasalamento_id UUID REFERENCES acasalamentos(id),
  embriao_id UUID REFERENCES embrioes(id),
  
  -- ClassificaÃ§Ã£o do biÃ³logo (ground truth)
  classification TEXT NOT NULL,  -- 'BE','BN','BX','BL','BI','Mo','Dg'
  stage_iets INT,                -- 1-9 (opcional)
  
  -- Embedding DINOv2 (imagem composta: morfologia + cinÃ©tica)
  embedding vector(768) NOT NULL,
  
  -- MÃ©tricas cinÃ©ticas (informativas)
  kinetic_intensity REAL,
  kinetic_harmony REAL,
  kinetic_symmetry REAL,
  kinetic_stability REAL,
  kinetic_bg_noise REAL,
  
  -- Imagens no Supabase Storage
  best_frame_path TEXT,
  motion_map_path TEXT,
  composite_path TEXT,
  crop_image_path TEXT,
  
  -- Resultado de DG (preenchido depois, quando disponÃ­vel)
  pregnancy_result BOOLEAN,      -- true = prenhou, false = nÃ£o, null = pendente
  pregnancy_checked_at TIMESTAMPTZ,
  
  -- Metadados
  ai_suggested_class TEXT,
  ai_confidence REAL,
  biologist_agreed BOOLEAN,
  
  -- ProteÃ§Ã£o contra classificaÃ§Ã£o errada
  review_mode TEXT DEFAULT 'standard',
  -- 'standard' = revisÃ£o normal do relatÃ³rio
  -- 'quick' = classificaÃ§Ã£o rÃ¡pida (menor peso futuro)
  -- 'expert' = revisada por especialista (maior peso futuro)
  
  -- Dados do setup (pra anÃ¡lise futura)
  microscope_model TEXT,
  camera_device TEXT,
  zoom_level TEXT,
  
  -- Cross-species (bootstrap com dados pÃºblicos)
  species TEXT NOT NULL DEFAULT 'bovine_real',
  -- 'bovine_real' = lab real, 'bovine_rocha' = dataset Rocha, 'human' = dataset Kromp
  source TEXT NOT NULL DEFAULT 'lab'
  -- 'lab' = classificaÃ§Ã£o real, 'dataset_rocha', 'dataset_kromp', 'dataset_kaggle'
);

-- Ãndice vetorial HNSW para busca KNN rÃ¡pida
CREATE INDEX embryo_refs_embedding_idx 
  ON embryo_references 
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_embryo_refs_class ON embryo_references(classification);
CREATE INDEX idx_embryo_refs_lab ON embryo_references(lab_id);
CREATE INDEX idx_embryo_refs_pregnancy ON embryo_references(pregnancy_result);
CREATE INDEX idx_embryo_refs_species ON embryo_references(species);
```

### 4c. FunÃ§Ã£o de busca KNN

```sql
CREATE OR REPLACE FUNCTION match_embryos(
  query_embedding vector(768),
  match_count INT DEFAULT 10,
  filter_lab_id UUID DEFAULT NULL,
  min_similarity FLOAT DEFAULT 0.65
)
RETURNS TABLE (
  id UUID,
  classification TEXT,
  similarity REAL,
  species TEXT,
  kinetic_intensity REAL,
  kinetic_harmony REAL,
  pregnancy_result BOOLEAN,
  best_frame_path TEXT,
  motion_map_path TEXT
)
LANGUAGE plpgsql AS $$
BEGIN
  RETURN QUERY
  SELECT
    er.id,
    er.classification,
    (1 - (er.embedding <=> query_embedding))::REAL as similarity,
    er.species,
    er.kinetic_intensity,
    er.kinetic_harmony,
    er.pregnancy_result,
    er.best_frame_path,
    er.motion_map_path
  FROM embryo_references er
  WHERE (filter_lab_id IS NULL OR er.lab_id = filter_lab_id)
    AND (1 - (er.embedding <=> query_embedding)) > min_similarity
  ORDER BY er.embedding <=> query_embedding ASC
  LIMIT match_count;
END;
$$;
```

**Nota:** Sem peso artificial por espÃ©cie. O DINOv2 jÃ¡ resolve isso naturalmente â€” embriÃµes bovinos reais (mesmo microscÃ³pio, mesma iluminaÃ§Ã£o) terÃ£o similaridade de cosseno maior com outros bovinos reais do que com embriÃµes humanos (setup diferente). Conforme dados reais acumulam, eles naturalmente dominam os resultados KNN. As colunas `species` e `source` existem para analytics, nÃ£o para ranking.

### 4d. Performance do pgvector

| Volume de referÃªncias | Tempo de busca KNN (10 vizinhos) |
|---|---|
| 1.000 | <10ms |
| 10.000 | <30ms |
| 100.000 | <50ms |
| 1.000.000 | <100ms (com Ã­ndice HNSW) |

### 4e. Alterar tabela embryo_scores

Adicionar campos novos, manter os antigos como nullable pra nÃ£o quebrar:

```sql
ALTER TABLE embryo_scores ADD COLUMN IF NOT EXISTS
  knn_classification TEXT,
  knn_confidence REAL,
  knn_votes JSONB,           -- {"BE":2,"BN":5,"BX":3}
  knn_neighbor_ids UUID[],
  knn_real_bovine_count INT, -- quantos vizinhos sÃ£o bovine_real
  embedding vector(768),
  kinetic_intensity REAL,
  kinetic_harmony REAL,
  kinetic_symmetry REAL,
  kinetic_stability REAL,
  kinetic_bg_noise REAL,
  motion_map_path TEXT,
  composite_path TEXT,
  biologist_classification TEXT,
  biologist_agreed BOOLEAN,
  -- Scoring dual (KNN + MLP)
  mlp_classification TEXT,         -- classificaÃ§Ã£o do MLP
  mlp_confidence REAL,             -- confianÃ§a do MLP (0-100)
  mlp_probabilities JSONB,         -- {"BE":5,"BN":62,"BX":20,"BL":8,"BI":3,"Mo":1,"Dg":1}
  combined_source TEXT,            -- 'knn' | 'knn_mlp_agree' | 'knn_mlp_disagree' | 'mlp_only' | 'insufficient'
  combined_classification TEXT,    -- classificaÃ§Ã£o final combinada
  combined_confidence REAL;        -- confianÃ§a final combinada
```

### 4f. Alterar tabela embryo_analysis_queue

```sql
ALTER TABLE embryo_analysis_queue ADD COLUMN IF NOT EXISTS
  plate_frame_path TEXT,        -- path do frame completo da placa no Storage
  detected_bboxes JSONB;        -- [{x_percent, y_percent, width_percent, height_percent}, ...]
```

### 4g. Buckets no Storage

```
embryoscore/
  {lote_fiv_id}/
    {acasalamento_id}/
      {queue_id}/
        plate_frame.jpg              â† frame completo da placa (1 por despacho)
        emb_{index}_frame.jpg        â† melhor frame do embriÃ£o
        emb_{index}_motion.jpg       â† mapa cinÃ©tico
        emb_{index}_composite.jpg    â† imagem composta (morph + cinÃ©tica)
```

### 4h. RLS de Storage

```sql
CREATE POLICY "labs_own_images" ON storage.objects
  FOR ALL USING (
    bucket_id = 'embryoscore' AND
    (storage.foldername(name))[1] = auth.uid()::text
  );
```

### 4i. Estimativa de storage

| Item | Tamanho | Volume (1 lab, 1 ano) | Total |
|---|---|---|---|
| Frame JPEG | ~100KB | 12.000 | ~1.2GB |
| Motion map JPEG | ~50KB | 12.000 | ~600MB |
| Composite JPEG | ~150KB | 12.000 | ~1.8GB |
| **Total por lab/ano** | | | **~3.6GB** |
| **50 labs/ano** | | | **~180GB** |

Custo Supabase Storage: ~R$25-50/mÃªs para 200GB.

---

## 5. NOVO CLOUD RUN: DINOv2 API

### 5.1 O que Ã© DINOv2

Modelo de visÃ£o computacional da Meta (Facebook AI Research). Open source, gratuito.

- **FunÃ§Ã£o:** Transforma qualquer imagem num vetor de 768 nÃºmeros (embedding)
- **Propriedade:** Imagens visualmente similares geram vetores prÃ³ximos
- **Tamanho:** ~85MB (ViT-B/14)
- **LatÃªncia:** ~200ms por imagem na GPU L4
- **Treinamento:** 142 milhÃµes de imagens (ImageNet-22k + LVD-142M)
- **LicenÃ§a:** Apache 2.0 (uso comercial permitido)

Por que DINOv2 e nÃ£o outros:
- **CLIP (OpenAI):** Feito para associar imagemâ†”texto, fraco em diferenÃ§as visuais sutis
- **ResNet/EfficientNet:** Precisam ser treinados do zero com dados anotados
- **DINOv2:** Especializado em **similaridade visual pura**, funciona out-of-the-box sem treino

### 5.2 Pipeline de processamento

```
ENTRADA: 40 crops JPEG (base64) de um embriÃ£o ao longo do tempo

PASSO 1 â€” Alinhamento de crops (template matching)
  - Alinha todos os crops ao primeiro (compensa deslocamento na placa)
  - cv2.matchTemplate â†’ calcula offset â†’ cv2.warpAffine
  - Descarta crops com deslocamento > 20px

PASSO 2 â€” SeleÃ§Ã£o do melhor crop (Laplacian variance)
  - Converte cada crop para grayscale
  - Aplica kernel Laplaciano
  - Crop com maior variÃ¢ncia = mais nÃ­tido

PASSO 3 â€” Mapa de movimento (diff pixels com subtraÃ§Ã£o de ruÃ­do)
  - Para cada par de crops consecutivos:
    - Calcula diferenÃ§a absoluta por pixel (mÃ©dia RGB)
    - Acumula diferenÃ§as num mapa 2D
  - SubtraÃ§Ã£o de ruÃ­do de fundo:
    - Define zona de referÃªncia: 15% das bordas do crop
    - Calcula mÃ©dia de movimento nas bordas (= ruÃ­do do setup)
    - Subtrai ruÃ­do Ã— 1.2 (margem de seguranÃ§a) de todo o mapa
    - Pixels com valor < 0 â†’ 0
  - Normaliza mapa para 0-255
  - Aplica colormap HOT: preto â†’ verde â†’ amarelo â†’ branco

PASSO 4 â€” MÃ©tricas cinÃ©ticas (informativas, nÃ£o usadas no KNN)
  - Intensidade: mÃ©dia das diferenÃ§as entre frames (zona central)
  - Harmonia: 1 - (desvio padrÃ£o / mÃ©dia) das diferenÃ§as
  - Simetria: comparaÃ§Ã£o de atividade entre 4 quadrantes
  - Estabilidade: 1 - coeficiente de variaÃ§Ã£o das diferenÃ§as
  - RuÃ­do de fundo: valor mÃ©dio subtraÃ­do (qualidade da gravaÃ§Ã£o)
  NOTA: Estes valores nÃ£o tÃªm significado clÃ­nico atÃ© correlaÃ§Ã£o com DG.

PASSO 5 â€” ComposiÃ§Ã£o da imagem
  [Melhor crop (morfologia)] [Mapa de movimento (cinÃ©tica)]
  O DINOv2 processa esta imagem como um todo â†’ embedding captura ambos.

PASSO 6 â€” Embedding DINOv2
  - Redimensiona imagem composta para 224Ã—224
  - Normaliza (ImageNet mean/std)
  - Passa pelo DINOv2 ViT-B/14
  - Retorna vetor de 768 dimensÃµes

SAÃDA: embedding + imagens (base64) + mÃ©tricas cinÃ©ticas
```

### 5.3 SubtraÃ§Ã£o de ruÃ­do â€” detalhe tÃ©cnico

O mapa de movimento bruto captura **qualquer mudanÃ§a de pixel**, incluindo tremido da cÃ¢mera, ruÃ­do do sensor, artefatos de compressÃ£o H.264, oscilaÃ§Ã£o de luz, bolhas de ar no meio de cultura.

A subtraÃ§Ã£o funciona assim:
- As **bordas do crop** (15% de cada lado) sÃ£o zona de referÃªncia
- Nessa zona nÃ£o hÃ¡ embriÃ£o, apenas meio de cultura
- Qualquer movimento detectado ali Ã© **ruÃ­do do setup**
- Esse valor mÃ©dio Ã© subtraÃ­do de **todo o crop**
- O que sobra sÃ£o apenas movimentos que excedem o nÃ­vel de ruÃ­do

**LimitaÃ§Ã£o:** Se o embriÃ£o ocupa quase todo o crop (zoom muito alto), as bordas podem conter parte do embriÃ£o.

### 5.4 Imagem composta â€” por que funciona

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  â”‚     â–‘â–‘â–‘â–‘â–‘        â”‚
â”‚   Melhor frame   â”‚   â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘      â”‚
â”‚   (como o        â”‚   â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘      â”‚
â”‚    embriÃ£o       â”‚   â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘      â”‚
â”‚    aparece)      â”‚     â–‘â–‘â–‘â–‘â–‘       â”‚
â”‚                  â”‚                  â”‚
â”‚   MORFOLOGIA     â”‚  MAPA CINÃ‰TICO   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

O DINOv2 gera um **Ãºnico embedding** que captura ambas as informaÃ§Ãµes. Quando o KNN busca vizinhos similares, encontra embriÃµes que **parecem iguais E se movem de forma similar**. As relaÃ§Ãµes entre morfologia e cinÃ©tica emergem naturalmente dos dados, sem fÃ³rmulas ou pesos definidos manualmente.

### 5.5 CÃ³digo: app.py

```python
import io
import base64
import json
import numpy as np
import torch
import cv2
from PIL import Image
from torchvision import transforms
from fastapi import FastAPI, UploadFile, Form
from fastapi.responses import JSONResponse

app = FastAPI()

# Carrega DINOv2 uma vez no startup
model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')
model.eval().cuda()

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

BORDER_PCT = 0.15
NOISE_MARGIN = 1.2


@app.post("/analyze-embryo")
async def analyze_embryo(frames_json: str = Form(...)):
    """
    Recebe lista de crops JPEG (base64) de um embriÃ£o ao longo do tempo.
    Retorna: embedding + mapa cinÃ©tico + mÃ©tricas + imagens.
    """
    frame_list = json.loads(frames_json)
    
    crops = []
    for b64 in frame_list:
        img_bytes = base64.b64decode(b64)
        arr = np.frombuffer(img_bytes, np.uint8)
        frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
        if frame is not None:
            crops.append(frame)
    
    if len(crops) < 5:
        return JSONResponse({"error": "Crops insuficientes"}, 400)
    
    # 1. Alinha crops ao primeiro
    crops = align_crops(crops)
    
    # 2. Melhor crop (mais nÃ­tido)
    best_idx = select_sharpest(crops)
    best_frame = crops[best_idx]
    
    # 3. Mapa de movimento com subtraÃ§Ã£o de ruÃ­do
    motion_map, kinetics = compute_motion_map(crops)
    
    # 4. CompÃµe imagem lado a lado
    composite = compose_image(best_frame, motion_map)
    
    # 5. Embedding DINOv2
    tensor = transform(composite).unsqueeze(0).cuda()
    with torch.no_grad():
        emb = model(tensor)
    embedding = emb[0].cpu().tolist()
    
    # 6. Codifica imagens
    _, best_jpg = cv2.imencode('.jpg', best_frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
    _, motion_jpg = cv2.imencode('.jpg', motion_map, [cv2.IMWRITE_JPEG_QUALITY, 85])
    composite_bgr = cv2.cvtColor(np.array(composite), cv2.COLOR_RGB2BGR)
    _, comp_jpg = cv2.imencode('.jpg', composite_bgr, [cv2.IMWRITE_JPEG_QUALITY, 85])
    
    return {
        "embedding": embedding,
        "kinetics": kinetics,
        "best_frame_b64": base64.b64encode(best_jpg.tobytes()).decode(),
        "motion_map_b64": base64.b64encode(motion_jpg.tobytes()).decode(),
        "composite_b64": base64.b64encode(comp_jpg.tobytes()).decode(),
        "frame_count": len(crops),
        "best_frame_index": best_idx
    }


def align_crops(crops):
    """Alinha todos os crops ao primeiro via template matching."""
    reference = cv2.cvtColor(crops[0], cv2.COLOR_BGR2GRAY)
    aligned = [crops[0]]
    for i in range(1, len(crops)):
        gray = cv2.cvtColor(crops[i], cv2.COLOR_BGR2GRAY)
        result = cv2.matchTemplate(gray, reference, cv2.TM_CCOEFF_NORMED)
        _, _, _, max_loc = cv2.minMaxLoc(result)
        dy, dx = max_loc[1], max_loc[0]
        if abs(dx) < 20 and abs(dy) < 20:
            M = np.float32([[1, 0, -dx], [0, 1, -dy]])
            aligned.append(cv2.warpAffine(crops[i], M, (crops[i].shape[1], crops[i].shape[0])))
        else:
            aligned.append(crops[i])
    return aligned


def select_sharpest(frames):
    best_idx, best_val = 0, -1
    for i, f in enumerate(frames):
        gray = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)
        val = cv2.Laplacian(gray, cv2.CV_64F).var()
        if val > best_val:
            best_val = val
            best_idx = i
    return best_idx


def compute_motion_map(frames):
    h, w = frames[0].shape[:2]
    motion_raw = np.zeros((h, w), dtype=np.float64)
    bx, by = int(w * BORDER_PCT), int(h * BORDER_PCT)
    border_mask = np.ones((h, w), dtype=bool)
    border_mask[by:h-by, bx:w-bx] = False
    center_mask = ~border_mask
    
    diffs = []
    for i in range(1, len(frames)):
        diff = cv2.absdiff(frames[i], frames[i-1]).mean(axis=2)
        motion_raw += diff
        border_mean = diff[border_mask].mean() if border_mask.any() else 0
        center_mean = diff[center_mask].mean() if center_mask.any() else 0
        diffs.append(max(0, center_mean - border_mean))
    
    bg_noise = float(motion_raw[border_mask].mean()) if border_mask.any() else 0
    threshold = bg_noise * NOISE_MARGIN
    motion_clean = np.maximum(0, motion_raw - threshold)
    
    if motion_clean.max() > 0:
        motion_norm = (motion_clean / motion_clean.max() * 255).astype(np.uint8)
    else:
        motion_norm = np.zeros((h, w), dtype=np.uint8)
    
    motion_colored = cv2.applyColorMap(motion_norm, cv2.COLORMAP_HOT)
    
    d = np.array(diffs) if diffs else np.array([0])
    intensity = float(d.mean())
    harmony = float(1 - min(1, d.std() / (intensity + 0.001)))
    stability = float(1 - min(1, (d.std() / (intensity + 0.001)) if intensity > 0 else 0))
    half_h, half_w = h // 2, w // 2
    quads = [motion_norm[:half_h,:half_w].mean(), motion_norm[:half_h,half_w:].mean(),
             motion_norm[half_h:,:half_w].mean(), motion_norm[half_h:,half_w:].mean()]
    q_mean, q_std = np.mean(quads), np.std(quads)
    symmetry = float(1 - min(1, q_std / (q_mean + 0.001)))
    
    return motion_colored, {
        "intensity": round(intensity, 4), "harmony": round(harmony, 4),
        "symmetry": round(symmetry, 4), "stability": round(stability, 4),
        "background_noise": round(bg_noise, 2)
    }


def compose_image(frame, motion_map):
    h, w = frame.shape[:2]
    motion_resized = cv2.resize(motion_map, (w, h))
    composite = np.hstack([frame, motion_resized])
    return Image.fromarray(cv2.cvtColor(composite, cv2.COLOR_BGR2RGB))


@app.get("/health")
async def health():
    return {"status": "ok", "model": "dinov2_vitb14"}
```

### 5.6 Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

RUN apt-get update && apt-get install -y --no-install-recommends \
    libgl1-mesa-glx libglib2.0-0 && rm -rf /var/lib/apt/lists/*

RUN pip install --no-cache-dir \
    torch torchvision --index-url https://download.pytorch.org/whl/cu121 \
    fastapi uvicorn pillow numpy opencv-python-headless python-multipart

COPY app.py .

# Baixa o modelo na build (nÃ£o no runtime)
RUN python -c "import torch; torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')"

EXPOSE 8080
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8080"]
```

### 5.7 Deploy

```bash
gcloud builds submit --tag gcr.io/SEU_PROJETO/embryoscore-dinov2

gcloud run deploy embryoscore-dinov2 \
  --image gcr.io/SEU_PROJETO/embryoscore-dinov2 \
  --gpu 1 --gpu-type nvidia-l4 \
  --cpu 4 --memory 16Gi \
  --max-instances 3 --min-instances 0 \
  --region us-central1 \
  --timeout 60
```

### 5.8 Custos estimados

| Escala | GPU Cloud Run | Gemini (recorte) | Supabase | Total/mÃªs |
|---|---|---|---|---|
| 1 lab (50/dia) | R$1 | R$33 | R$0 (free tier) | ~R$34 |
| 10 labs | R$10 | R$330 | R$25 | ~R$365 |
| 50 labs | R$49 | R$1.650 | R$50 | ~R$1.750 |

Custo DINOv2 por inferÃªncia: ~R$0,001 (0.5s de GPU L4 a $0.000233/s).

---

## 6. CLOUD RUN EXISTENTE: NOVOS ENDPOINTS

### 6a. MANTER `/extract-frame` (nÃ£o mexer)

### 6b. NOVO: `/extract-and-crop`

Resolve o problema de memÃ³ria. Recebe video_url + bboxes, extrai 40 frames internamente, recorta cada embriÃ£o, retorna sÃ³ os crops pequenos. Os 40 frames completos nascem e morrem aqui.

```python
@app.post("/extract-and-crop")
async def extract_and_crop(request: dict):
    """
    Recebe: { video_url, bboxes: [...], frame_count: 40 }
    Retorna: { embryos: { "0": [crop_b64, ...], "1": [...] }, plate_frame_b64, frames_extracted }
    Os 40 frames completos NUNCA saem deste serviÃ§o.
    """
    video_url = request['video_url']
    bboxes = request['bboxes']
    frame_count = request.get('frame_count', 40)
    
    video_path = download_video(video_url)
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    step = max(1, total_frames // frame_count)
    
    embryo_crops = {str(i): [] for i in range(len(bboxes))}
    plate_frame_b64 = None
    frame_idx = 0
    extracted = 0
    
    while cap.isOpened() and extracted < frame_count:
        ret, frame = cap.read()
        if not ret:
            break
        if frame_idx % step == 0:
            h, w = frame.shape[:2]
            
            # Salva frame 0 completo como plate_frame
            if plate_frame_b64 is None:
                _, plate_jpg = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
                plate_frame_b64 = base64.b64encode(plate_jpg.tobytes()).decode()
            
            # Recorta cada embriÃ£o neste frame
            for emb_idx, bbox in enumerate(bboxes):
                x1 = int((bbox['x_percent'] / 100 - bbox['width_percent'] / 200) * w)
                y1 = int((bbox['y_percent'] / 100 - bbox['height_percent'] / 200) * h)
                x2 = int((bbox['x_percent'] / 100 + bbox['width_percent'] / 200) * w)
                y2 = int((bbox['y_percent'] / 100 + bbox['height_percent'] / 200) * h)
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(w, x2), min(h, y2)
                
                crop = frame[y1:y2, x1:x2]
                if crop.size > 0:
                    _, crop_jpg = cv2.imencode('.jpg', crop, [cv2.IMWRITE_JPEG_QUALITY, 80])
                    embryo_crops[str(emb_idx)].append(
                        base64.b64encode(crop_jpg.tobytes()).decode()
                    )
            extracted += 1
        frame_idx += 1
    
    cap.release()
    os.remove(video_path)
    
    return {
        "embryos": embryo_crops,
        "plate_frame_b64": plate_frame_b64,
        "frames_extracted": extracted
    }
```

### 6c. DEPRECAR `/analyze-activity`

```python
@app.post("/analyze-activity")
async def analyze_activity_deprecated():
    return {"error": "Deprecated. Use embryoscore-dinov2 /analyze-embryo", "status": "deprecated"}
```

---

## 7. EDGE FUNCTION: REESCREVER

### Arquivo: `supabase/functions/embryo-analyze/index.ts`

Estrutura geral se mantÃ©m. ConteÃºdo dos passos muda.

```typescript
// ============================================================
// EDGE FUNCTION â€” EMBRYO ANALYZE v2
// ============================================================

// PASSO 1: Buscar job, status â†’ processing (IGUAL AO ATUAL)
const job = await supabase.from('embryo_analysis_queue')
  .select('*').eq('id', queue_id).single();
await supabase.from('embryo_analysis_queue')
  .update({ status: 'processing' }).eq('id', queue_id);


// PASSO 2: Extrair 1 frame para detecÃ§Ã£o (IGUAL AO ATUAL)
const frameResponse = await fetch(`${CLOUD_RUN_URL}/extract-frame`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ video_url: mediaUrl, position: 0.5 })
});
const { frame: detectionFrame } = await frameResponse.json();


// PASSO 3: Detectar embriÃµes com Gemini box_2d (IGUAL AO ATUAL)
const bboxes = await detectEmbryosGemini(detectionFrame);


// PASSO 4: Extrair e recortar no Cloud Run (NOVO)
// Os 40 frames NUNCA chegam aqui.
const cropResponse = await fetch(`${CLOUD_RUN_URL}/extract-and-crop`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ video_url: mediaUrl, bboxes, frame_count: 40 })
});
const cropData = await cropResponse.json();
// cropData.embryos = { "0": [40 crops], "1": [40 crops], ... }
// cropData.plate_frame_b64 = frame completo da placa


// PASSO 4b: Salvar frame da placa e bboxes (NOVO)
await supabase.storage.from('embryoscore').upload(
  `${lote_fiv_id}/${acasalamento_id}/${queue_id}/plate_frame.jpg`,
  base64ToBuffer(cropData.plate_frame_b64),
  { contentType: 'image/jpeg' }
);
await supabase.from('embryo_analysis_queue').update({
  plate_frame_path: `${lote_fiv_id}/${acasalamento_id}/${queue_id}/plate_frame.jpg`,
  detected_bboxes: bboxes
}).eq('id', queue_id);


// PASSO 5: Analisar com DINOv2 (NOVO â€” em PARALELO)
const DINOV2_URL = Deno.env.get('DINOV2_CLOUD_RUN_URL');

const analyzePromises = Object.entries(cropData.embryos).map(
  async ([embIdx, crops]) => {
    const formData = new FormData();
    formData.append('frames_json', JSON.stringify(crops));
    const response = await fetch(`${DINOV2_URL}/analyze-embryo`, {
      method: 'POST', body: formData
    });
    return { embIdx: parseInt(embIdx), result: await response.json() };
  }
);
const analyzeResults = await Promise.all(analyzePromises);


// PASSO 6: KNN no Supabase (NOVO â€” em PARALELO)
const MIN_SIMILARITY = 0.65;
const MIN_NEIGHBORS = 3;

const knnPromises = analyzeResults.map(async ({ embIdx, result }) => {
  const { data: neighbors } = await supabase.rpc('match_embryos', {
    query_embedding: result.embedding, match_count: 10
  });
  
  const goodNeighbors = (neighbors || []).filter(
    (n: any) => n.similarity >= MIN_SIMILARITY
  );
  
  let knnResult;
  if (goodNeighbors.length < MIN_NEIGHBORS) {
    knnResult = {
      classification: null, confidence: 0,
      votes: {}, status: 'insufficient_data'
    };
  } else {
    const votes: Record<string, number> = {};
    for (const n of goodNeighbors) {
      votes[n.classification] = (votes[n.classification] || 0) + 1;
    }
    const sorted = Object.entries(votes).sort((a, b) => b[1] - a[1]);
    
    const withDG = goodNeighbors.filter((n: any) => n.pregnancy_result !== null);
    const pregnancyRate = withDG.length >= 5
      ? Math.round(withDG.filter((n: any) => n.pregnancy_result).length / withDG.length * 100)
      : null;
    
    knnResult = {
      classification: sorted[0][0],
      confidence: Math.round((sorted[0][1] / goodNeighbors.length) * 100),
      votes: Object.fromEntries(sorted),
      status: 'ok',
      pregnancy_prediction: pregnancyRate,
      pregnancy_sample_size: withDG.length
    };
  }
  return { embIdx, knnResult };
});
const knnResults = await Promise.all(knnPromises);


// PASSO 7: Salvar imagens no Storage
for (const { embIdx, result } of analyzeResults) {
  const basePath = `${lote_fiv_id}/${acasalamento_id}/${queue_id}`;
  await Promise.all([
    supabase.storage.from('embryoscore').upload(
      `${basePath}/emb_${embIdx}_frame.jpg`,
      base64ToBuffer(result.best_frame_b64), { contentType: 'image/jpeg' }),
    supabase.storage.from('embryoscore').upload(
      `${basePath}/emb_${embIdx}_motion.jpg`,
      base64ToBuffer(result.motion_map_b64), { contentType: 'image/jpeg' }),
    supabase.storage.from('embryoscore').upload(
      `${basePath}/emb_${embIdx}_composite.jpg`,
      base64ToBuffer(result.composite_b64), { contentType: 'image/jpeg' }),
  ]);
}


// PASSO 8: Salvar scores
await supabase.from('embryo_scores')
  .update({ is_current: false }).in('embriao_id', embryoIds);

for (const { embIdx, result } of analyzeResults) {
  const knn = knnResults.find(k => k.embIdx === embIdx)!.knnResult;
  const basePath = `${lote_fiv_id}/${acasalamento_id}/${queue_id}`;
  
  await supabase.from('embryo_scores').insert({
    embriao_id: embryoIds[embIdx],
    queue_id, is_current: true, analysis_version: nextVersion,
    knn_classification: knn.classification,
    knn_confidence: knn.confidence,
    knn_votes: knn.votes,
    embedding: result.embedding,
    kinetic_intensity: result.kinetics.intensity,
    kinetic_harmony: result.kinetics.harmony,
    kinetic_symmetry: result.kinetics.symmetry,
    kinetic_stability: result.kinetics.stability,
    kinetic_bg_noise: result.kinetics.background_noise,
    crop_image_path: `${basePath}/emb_${embIdx}_frame.jpg`,
    motion_map_path: `${basePath}/emb_${embIdx}_motion.jpg`,
    composite_path: `${basePath}/emb_${embIdx}_composite.jpg`,
    bbox_x: bboxes[embIdx].x_percent,
    bbox_y: bboxes[embIdx].y_percent,
    bbox_w: bboxes[embIdx].width_percent,
    bbox_h: bboxes[embIdx].height_percent,
    classification: knn.classification,
    confidence: knn.confidence
  });
}


// PASSO 9: Status completed (IGUAL)
await supabase.from('embryo_analysis_queue')
  .update({ status: 'completed', completed_at: new Date().toISOString() })
  .eq('id', queue_id);
```

---

## 8. FRONTEND

**REGRA: Todos os componentes seguem PassaGene DS (seÃ§Ã£o 18).**

### 8a. EmbryoReviewPanel.tsx (CRIAR)

Painel principal da revisÃ£o prÃ©-despacho. O biÃ³logo usa DEPOIS do envase, ao conferir o relatÃ³rio. ContÃ©m:
1. PlatePanorama no topo (navegaÃ§Ã£o visual)
2. Card do embriÃ£o sendo revisado
3. Progresso "12/15 classificados"
4. DispatchSummary quando todos classificados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RevisÃ£o â€” Lote FIV #234              12/15 âœ“    â”‚
â”‚                                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚           PLACA PANORÃ‚MICA                  â”‚ â”‚
â”‚ â”‚   â‘ âœ“    â‘¡âœ“    â‘¢âœ“    â‘£â–¶    â‘¤â—‹              â”‚ â”‚
â”‚ â”‚   â‘¥âœ“    â‘¦âœ“    â‘§âœ“    â‘¨âœ“    â‘©âœ“              â”‚ â”‚
â”‚ â”‚   â‘ªâœ“    â‘«âœ“    â‘¬â—‹    â‘­â—‹    â‘®â—‹              â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  âœ“ = classificado   â–¶ = revisando   â—‹ = pendenteâ”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚ EmbriÃ£o #4                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚ â”‚  â”‚ Melhor   â”‚  â”‚  Mapa    â”‚  â”‚ Minimapa â”‚  â”‚ â”‚
â”‚ â”‚  â”‚  frame   â”‚  â”‚ cinÃ©tico â”‚  â”‚ da placa â”‚  â”‚ â”‚
â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚ â”‚  ğŸ¤– BN (78%) â€” KNN + Classificador concordam âœ“  â”‚ â”‚
â”‚ â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ BN  50%                       â”‚ â”‚
â”‚ â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ BE  20%                       â”‚ â”‚
â”‚ â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ BX  20%                       â”‚ â”‚
â”‚ â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ BL  10%                       â”‚ â”‚
â”‚ â”‚  [BE] [BNâœ¨] [BX] [BL] [BI] [Mo] [Dg]     â”‚ â”‚
â”‚ â”‚  [      Confirmar â†’ prÃ³ximo #5      ]       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ Quando todos âœ“:                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Resumo: 5 BE, 4 BN, 3 BX, 2 BL, 1 Dg     â”‚ â”‚
â”‚ â”‚ ConcordÃ¢ncia IA: 80% (12/15)               â”‚ â”‚
â”‚ â”‚ Atlas: 2.826 cross-species + 147 reais     â”‚ â”‚
â”‚ â”‚ [      Confirmar despacho      ]            â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8b. PlatePanorama.tsx (CRIAR)

Frame completo da placa com embriÃµes numerados. Canvas interativo:
- Pendente (â—‹): borda branca 50% opacidade
- Classificado (âœ“): preenchido primary-subtle, borda primary
- Selecionado (â–¶): preenchido primary, borda primary-dark, pulso animado
- Tocar num embriÃ£o â†’ scrolla atÃ© ele

### 8c. EmbryoMinimap.tsx (CRIAR)

Canvas 120Ã—90px no canto do card individual. Frame completo reduzido com marcador verde no embriÃ£o atual. SÃ³ visual, sem interaÃ§Ã£o.

```tsx
function EmbryoMinimap({ plateFrameUrl, bboxes, currentIndex }: Props) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas || !plateFrameUrl) return;
    const ctx = canvas.getContext('2d');
    const img = new Image();
    img.crossOrigin = 'anonymous';
    img.onload = () => {
      canvas.width = 120; canvas.height = 90;
      ctx.drawImage(img, 0, 0, 120, 90);
      bboxes.forEach((bbox, i) => {
        const x = (bbox.x_percent / 100) * 120;
        const y = (bbox.y_percent / 100) * 90;
        ctx.beginPath();
        if (i === currentIndex) {
          ctx.arc(x, y, 7, 0, Math.PI * 2);
          ctx.fillStyle = '#2ECC71';
          ctx.fill();
          ctx.strokeStyle = '#1E8449';
          ctx.lineWidth = 2;
        } else {
          ctx.arc(x, y, 4, 0, Math.PI * 2);
          ctx.strokeStyle = 'rgba(255,255,255,0.4)';
          ctx.lineWidth = 1;
        }
        ctx.stroke();
      });
    };
    img.src = plateFrameUrl;
  }, [plateFrameUrl, bboxes, currentIndex]);
  return <canvas ref={canvasRef} className="rounded-lg border border-border" style={{ width: 120, height: 90 }} />;
}
```

### 8d. EmbryoScoreCard.tsx (REESCREVER)

| Antes (Gemini) | Depois (KNN + MLP dual) |
|---|---|
| `embryo_score` (0-100) | Remover |
| `morph_score`, `kinetic_score` | Remover |
| Sub-scores MCI/TE/ZP/Frag | Remover |
| `reasoning`, `quality_checklist` | Remover |
| `transfer_recommendation` | Remover |
| â€” | **NOVO:** Melhor frame + mapa cinÃ©tico + minimapa |
| â€” | **NOVO:** Barras de votaÃ§Ã£o KNN (ponderadas por espÃ©cie) |
| â€” | **NOVO:** Indicador de fonte: KNN / KNN+MLP concordam / KNN+MLP divergem / MLP only |
| â€” | **NOVO:** Indicador "Aprendendo..." com contagem de referÃªncias reais |
| â€” | **NOVO:** BotÃµes classificaÃ§Ã£o biÃ³logo |

**Indicadores visuais por fonte de scoring:**

```
source = 'knn' (atlas maduro, 200+ refs reais):
  ğŸ¤– BN (78%) â€” 10 embriÃµes similares
  Barras de votaÃ§Ã£o normais

source = 'knn_mlp_agree' (concordÃ¢ncia):
  ğŸ¤– BN (72%) â€” KNN + Classificador concordam âœ“
  Barras de votaÃ§Ã£o normais + badge verde "concordam"

source = 'knn_mlp_disagree' (divergÃªncia):
  ğŸ¤– BN (55%) vs ğŸ’¡ BX (48%)
  Duas linhas de votaÃ§Ã£o lado a lado, destaque visual na divergÃªncia

source = 'mlp_only' (atlas imaturo):
  ğŸ’¡ BN (62%) â€” SugestÃ£o do classificador
  ğŸ” 23 referÃªncias reais no atlas â€” classifique manualmente
  Barras de probabilidade do MLP (nÃ£o Ã© votaÃ§Ã£o KNN)

source = 'insufficient' (tudo insuficiente):
  ğŸ” Aprendendo... Classifique manualmente (5 referÃªncias)
  Sem sugestÃ£o, sem barras
```

### 8e. BiologistClassButtons.tsx (CRIAR)

BotÃµes de classe (BE/BN/BX/BL/BI/Mo/Dg). Ao confirmar:
1. Atualiza `embryo_scores` (biologist_classification, biologist_agreed)
2. Insere em `embryo_references` (embedding + classe + imagens + **species='bovine_real'**) â†’ Atlas cresce
3. Chama onClassified() â†’ avanÃ§a pro prÃ³ximo pendente
4. BotÃ£o "desfazer" em atÃ© 5 minutos

### 8f. LoteScoreDashboard.tsx (REESCREVER)

DistribuiÃ§Ã£o por classe (barras) em vez de score mÃ©dio. ConcordÃ¢ncia biÃ³logo Ã— IA. **NOVO:** Indicador de maturidade do atlas: "Atlas: 2.826 cross-species + 147 reais" com barra de progresso.

### 8g. DispatchSummary.tsx (CRIAR)

Resumo final: contagem por classe, concordÃ¢ncia, botÃ£o "Confirmar despacho".

### 8h. LÃ³gica de votaÃ§Ã£o (frontend) â€” simples, sem peso artificial

```typescript
function computeVotes(neighbors: Neighbor[]) {
  const votes: Record<string, number> = {};

  for (const n of neighbors) {
    votes[n.classification] = (votes[n.classification] || 0) + 1;
  }

  const sorted = Object.entries(votes).sort((a, b) => b[1] - a[1]);
  const winner = sorted[0][0];
  const confidence = Math.round((sorted[0][1] / neighbors.length) * 100);

  // Contagem de vizinhos reais vs cross-species (informativo)
  const realBovine = neighbors.filter(n => n.species === 'bovine_real').length;

  // PrediÃ§Ã£o de prenhez (sÃ³ com dados reais bovinos que tÃªm DG)
  const withDG = neighbors.filter(n =>
    n.pregnancy_result !== null && n.species === 'bovine_real'
  );
  const pregnancyRate = withDG.length >= 5
    ? Math.round(withDG.filter(n => n.pregnancy_result).length / withDG.length * 100)
    : null;

  return {
    classification: winner,
    confidence,
    votes: Object.fromEntries(sorted),
    total_neighbors: neighbors.length,
    real_bovine_neighbors: realBovine,
    source: realBovine >= 3 ? 'knn_real' : realBovine >= 1 ? 'knn_mixed' : 'knn_cross_species',
    pregnancyPrediction: pregnancyRate,
    pregnancySampleSize: withDG.length
  };
}
```

---

## 9. O QUE REMOVER

| O que | AÃ§Ã£o |
|---|---|
| Prompt Gemini V4 (~330 linhas) na Edge Function | **Deletar** |
| Chamada Gemini avaliaÃ§Ã£o morfolÃ³gica | **Deletar** |
| Parse GeminiV4Result | **Deletar** |
| Cloud Run `/analyze-activity` | **Deprecar** |
| Sub-scores MCI/TE/ZP/Frag na UI | **Remover** |
| Reasoning/checklist/transfer_recommendation na UI | **Remover** |

**NÃƒO deletar tabelas ou colunas.** SÃ³ adicionar novas e parar de usar as antigas. Permite rollback.

---

## 10. ATLAS INICIAL (BOOTSTRAP CROSS-SPECIES)

### 10.1 O problema do banco vazio

No dia 1, o KNN nÃ£o tem referÃªncias. Sem referÃªncias, sem sugestÃ£o. Com a abordagem anterior (35 embriÃµes manuais), o sistema precisava de semanas pra atingir massa crÃ­tica.

### 10.2 Insight: Transfer Learning Cross-Species

A morfologia embrionÃ¡ria Ã© conservada entre mamÃ­feros. Humano e bovino compartilham as mesmas estruturas visuais avaliadas por embriologistas:

| Estrutura | Humano | Bovino | AvaliaÃ§Ã£o visual |
|---|---|---|---|
| Blastocoel | Cavidade fluida | Cavidade fluida | IdÃªntica |
| ICM (Massa Celular Interna) | Aglomerado celular | Aglomerado celular | IdÃªntica |
| Trofoectoderma (TE) | Camada externa | Camada externa | IdÃªntica |
| Zona PelÃºcida | Casca externa | Casca externa | IdÃªntica |
| FragmentaÃ§Ã£o | Debris celular | Debris celular | IdÃªntica |

**Base cientÃ­fica:** Review de 2024 (Frontiers in Veterinary Science) recomenda explicitamente: "as abordagens bem-sucedidas em estudos humanos devem ser investigadas para embriÃµes bovinos com modificaÃ§Ãµes apropriadas". Paper de 2020 (Development) confirma: "semelhanÃ§as na arquitetura embrionÃ¡ria entre mamÃ­feros eutÃ©rios sugerem mecanismos comuns guiando o desenvolvimento prÃ©-implantaÃ§Ã£o".

**DiferenÃ§as relevantes:**
- Citoplasma bovino Ã© mais escuro (dificulta visualizaÃ§Ã£o)
- MicroscÃ³pio diferente (estereomicroscÃ³pio bovino vs invertido humano â†’ imagens parecem diferentes)
- Tamanho ligeiramente diferente (bovino ~150-190Î¼m vs humano ~120-150Î¼m)
- Velocidade de desenvolvimento (bovino D7 vs humano D5-6)

**ConclusÃ£o:** O DINOv2 captura ESTRUTURA VISUAL, nÃ£o espÃ©cie. Os embeddings de um blastocisto humano e bovino de qualidade similar terÃ£o proximidade no espaÃ§o vetorial â€” nÃ£o idÃªnticos, mas prÃ³ximos o suficiente pra bootstrap.

### 10.3 Datasets pÃºblicos disponÃ­veis

| Dataset | EspÃ©cie | Volume | AnotaÃ§Ãµes | Fonte |
|---|---|---|---|---|
| Kromp et al. 2023 | Humano | 2.344 blastocistos | Gardner (EXP + ICM + TE) + parÃ¢metros clÃ­nicos | Figshare pÃºblico |
| Rocha et al. 2017 | Bovino | 482 blastocistos | IETS 1/2/3 por 3 embriologistas | Figshare pÃºblico |
| Kaggle Embryo Classification | Humano | ~1.000 | Blastocisto/nÃ£o-blastocisto | Kaggle |

**Links:**
- Kromp: `https://doi.org/10.6084/m9.figshare.20123153.v3`
- Rocha: `https://doi.org/10.6084/m9.figshare.c.3825241`

### 10.4 Mapeamento de classificaÃ§Ãµes Gardner â†’ IETS â†’ PassaGene

```
Gardner (humano)                      IETS (bovino)        PassaGene
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EXP 3-6 + ICM A + TE a              Stage 4-7, Grade 1   â†’ BE
EXP 3-6 + ICM A + TE b              Stage 4-7, Grade 1-2 â†’ BN
EXP 3-6 + ICM B + TE a              Stage 4-7, Grade 1-2 â†’ BN
EXP 3-6 + ICM B + TE b              Stage 4-7, Grade 2   â†’ BX
EXP 3-6 + ICM B + TE c              Stage 4-7, Grade 2-3 â†’ BL
EXP 3-6 + ICM C + TE b              Stage 4-7, Grade 3   â†’ BL
EXP 3-6 + ICM C + TE c              Stage 4-7, Grade 3-4 â†’ BI
EXP 1-2 (sem expansÃ£o)              Stage 1-3            â†’ Mo
Degenerado/fragmentado               Degenerado           â†’ Dg
```

Mapeamento Ã© APROXIMADO e conservador. EmbriÃµes humanos mapeados com flag `species: 'human'` e peso reduzido no KNN.

### 10.5 EstratÃ©gia de bootstrap em 3 camadas

```
CAMADA 1 â€” Atlas Cross-Species (dia 0, antes do lab usar)
â”œâ”€â”€ 2.344 imagens humanas (Kromp) â†’ embedding DINOv2 â†’ atlas com flag species='human'
â”œâ”€â”€ 482 imagens bovinas (Rocha) â†’ embedding DINOv2 â†’ atlas com flag species='bovine_rocha'
â”œâ”€â”€ ClassificaÃ§Ãµes mapeadas Gardnerâ†’PassaGene e IETSâ†’PassaGene
â”œâ”€â”€ Sem peso artificial: DINOv2 jÃ¡ prioriza embriÃµes de setup similar por similaridade natural
â””â”€â”€ Total: ~2.826 referÃªncias no atlas ANTES do primeiro uso

CAMADA 2 â€” Classificador MLP treinado (deploy junto com DINOv2)
â”œâ”€â”€ MLP simples: 768d â†’ 256 â†’ 7 classes (BE/BN/BX/BL/BI/Mo/Dg)
â”œâ”€â”€ Treinado com embeddings das 2.826 referÃªncias cross-species
â”œâ”€â”€ Funciona como segunda opiniÃ£o PARALELA ao KNN
â”œâ”€â”€ Peso dinÃ¢mico: alto no inÃ­cio, diminui conforme atlas cresce
â””â”€â”€ Custo: zero (roda no mesmo container DINOv2)

CAMADA 3 â€” Fallback IA Generativa (quando KNN + MLP insuficientes)
â”œâ”€â”€ Modelo de visÃ£o forte (GPT-4o ou Claude) com prompt contextualizado
â”œâ”€â”€ Prompt inclui: critÃ©rios detalhados + 2-3 fotos exemplo por classe
â”œâ”€â”€ Ativado SOMENTE quando KNN retorna insufficient_data E MLP tem baixa confianÃ§a
â”œâ”€â”€ SugestÃ£o aparece como "ğŸ’¡ SugestÃ£o provisÃ³ria" (nunca como classificaÃ§Ã£o definitiva)
â”œâ”€â”€ Custo: ~R$0.05-0.10/embriÃ£o (temporÃ¡rio, primeiras semanas)
â””â”€â”€ Desativado automaticamente quando atlas atinge 200+ referÃªncias bovinas reais
```

### 10.6 Campos species/source na tabela embryo_references

JÃ¡ definidos na seÃ§Ã£o 4b. Os campos `species` e `source` sÃ£o para analytics e rastreabilidade, NÃƒO para ponderaÃ§Ã£o no KNN. A similaridade de cosseno do DINOv2 jÃ¡ prioriza embriÃµes de setup similar naturalmente.

### 10.7 LÃ³gica de votaÃ§Ã£o (Edge Function)

```typescript
// VotaÃ§Ã£o simples â€” sem peso artificial, similaridade natural basta
function computeVote(neighbors: NeighborRow[]) {
  const votes: Record<string, number> = {};

  for (const n of neighbors) {
    votes[n.classification] = (votes[n.classification] || 0) + 1;
  }

  const sorted = Object.entries(votes).sort((a, b) => b[1] - a[1]);
  const winner = sorted[0];

  // Contar quantos vizinhos sÃ£o bovine_real (dados reais do lab)
  const realBovineCount = neighbors.filter(n => n.species === 'bovine_real').length;

  return {
    classification: winner[0],
    confidence: Math.round((winner[1] / neighbors.length) * 100),
    total_neighbors: neighbors.length,
    real_bovine_neighbors: realBovineCount,
    votes: Object.fromEntries(sorted),
    // Fonte da sugestÃ£o: informativo pro frontend
    source: realBovineCount >= 3 ? 'knn_real' : realBovineCount >= 1 ? 'knn_mixed' : 'knn_cross_species'
  };
}
```

### 10.8 Scoring dual: KNN + classificador MLP

```python
# No container DINOv2 Cloud Run - endpoint /analyze-embryo ATUALIZADO
# O classificador MLP Ã© carregado junto com o DINOv2

import torch
import torch.nn as nn

class EmbryoClassifier(nn.Module):
    """MLP simples treinado com dados cross-species."""
    def __init__(self, input_dim=768, hidden_dim=256, num_classes=7):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, num_classes)
        )
        self.classes = ['BE', 'BN', 'BX', 'BL', 'BI', 'Mo', 'Dg']

    def forward(self, x):
        return self.net(x)

    def predict(self, embedding_tensor):
        with torch.no_grad():
            logits = self.forward(embedding_tensor)
            probs = torch.softmax(logits, dim=-1)
            top_prob, top_idx = probs.max(dim=-1)
            return {
                'classification': self.classes[top_idx.item()],
                'confidence': round(top_prob.item() * 100),
                'probabilities': {
                    cls: round(p.item() * 100)
                    for cls, p in zip(self.classes, probs[0])
                }
            }

# Carregamento no startup do container
classifier = EmbryoClassifier()
classifier.load_state_dict(torch.load('embryo_classifier.pth', map_location='cpu'))
classifier.eval()

# Endpoint /analyze-embryo retorna AMBOS
@app.post("/analyze-embryo")
async def analyze_embryo(file: UploadFile):
    # ... (processamento existente: align, sharpen, motion, composite)
    embedding = compute_embedding(composite)

    # Classificador MLP (paralelo, custo zero)
    mlp_result = classifier.predict(torch.tensor(embedding).unsqueeze(0))

    return {
        "embedding": embedding.tolist(),
        "composite_image": composite_b64,
        "best_frame": best_frame_b64,
        "motion_map": motion_b64,
        "mlp_classification": mlp_result  # NOVO
    }
```

### 10.9 LÃ³gica combinada na Edge Function

```typescript
// Edge Function: combinar KNN + MLP + fallback IA generativa
async function getCombinedScore(
  knnResult: KNNResult,
  mlpResult: MLPResult,
  atlasStats: { total: number; real_bovine: number }
) {
  // Peso dinÃ¢mico baseado na maturidade do atlas
  const realRefs = atlasStats.real_bovine;
  const knnWeight = Math.min(realRefs / 200, 1.0); // 0â†’1 conforme atlas cresce atÃ© 200
  const mlpWeight = 1.0 - knnWeight;

  // Caso 1: Atlas maduro (200+ referÃªncias bovinas reais) â†’ KNN domina
  if (realRefs >= 200 && knnResult.status !== 'insufficient_data') {
    return {
      classification: knnResult.classification,
      confidence: knnResult.confidence,
      source: 'knn',
      knn_detail: knnResult,
      mlp_detail: mlpResult,
      show_mlp: false  // MLP vira apenas verificaÃ§Ã£o interna
    };
  }

  // Caso 2: Atlas em crescimento â†’ combina KNN + MLP
  if (knnResult.status !== 'insufficient_data') {
    // Se concordam, confianÃ§a alta
    if (knnResult.classification === mlpResult.classification) {
      return {
        classification: knnResult.classification,
        confidence: Math.round(knnResult.confidence * 0.6 + mlpResult.confidence * 0.4),
        source: 'knn_mlp_agree',
        knn_detail: knnResult,
        mlp_detail: mlpResult,
        show_mlp: true
      };
    }
    // Se discordam, mostra ambos pro biÃ³logo decidir
    return {
      classification: knnResult.classification, // KNN tem prioridade visual
      confidence: Math.round(knnResult.confidence * knnWeight + mlpResult.confidence * mlpWeight),
      source: 'knn_mlp_disagree',
      knn_detail: knnResult,
      mlp_detail: mlpResult,
      show_mlp: true,
      disagreement: true
    };
  }

  // Caso 3: KNN insuficiente â†’ MLP sozinho
  if (mlpResult.confidence >= 50) {
    return {
      classification: mlpResult.classification,
      confidence: mlpResult.confidence,
      source: 'mlp_only',
      knn_detail: null,
      mlp_detail: mlpResult,
      show_mlp: true,
      learning: true
    };
  }

  // Caso 4: Tudo insuficiente â†’ sem sugestÃ£o, biÃ³logo classifica do zero
  return {
    classification: null,
    confidence: 0,
    source: 'insufficient',
    knn_detail: null,
    mlp_detail: mlpResult,
    show_mlp: false,
    learning: true
  };
}
```

### 10.10 UI do indicador cross-species

```
Quando source = 'knn' (atlas maduro):
  ğŸ¤– BN (78%)  â€” Baseado em 10 embriÃµes similares
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ BN 50%   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ BE 20%   â–ˆâ–ˆâ–ˆâ–ˆ BX 20%   â–ˆâ–ˆ BL 10%

Quando source = 'knn_mlp_agree':
  ğŸ¤– BN (72%)  â€” KNN + Classificador concordam
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ BN 50%   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ BE 20%   â–ˆâ–ˆâ–ˆâ–ˆ BX 20%   â–ˆâ–ˆ BL 10%

Quando source = 'knn_mlp_disagree':
  ğŸ¤– BN (55%) vs ğŸ’¡ BX (48%)  â€” DivergÃªncia KNN Ã— Classificador
  [indicador visual mostra ambas sugestÃµes]

Quando source = 'mlp_only':
  ğŸ’¡ BN (62%) â€” SugestÃ£o do classificador (aprendendo...)
  ğŸ” 23 referÃªncias no atlas â€” classifique manualmente

Quando source = 'insufficient':
  ğŸ” Aprendendo... Classifique manualmente (5 referÃªncias)
```

### 10.11 Script de bootstrap cross-species

```python
#!/usr/bin/env python3
"""
bootstrap_atlas.py â€” Popular atlas com datasets pÃºblicos cross-species.
Executar UMA VEZ antes do primeiro uso do sistema.
"""

import os, json, requests
import torch
from pathlib import Path

DINOV2_URL = os.environ['DINOV2_CLOUD_RUN_URL']
SUPABASE_URL = os.environ['SUPABASE_URL']
SUPABASE_KEY = os.environ['SUPABASE_SERVICE_KEY']

# Mapeamento Gardner â†’ PassaGene
GARDNER_TO_PASSAGENE = {
    # (ICM, TE) â†’ classe PassaGene
    ('A', 'a'): 'BE', ('A', 'b'): 'BN', ('A', 'c'): 'BX',
    ('B', 'a'): 'BN', ('B', 'b'): 'BX', ('B', 'c'): 'BL',
    ('C', 'a'): 'BX', ('C', 'b'): 'BL', ('C', 'c'): 'BI',
}

# Mapeamento IETS â†’ PassaGene
IETS_TO_PASSAGENE = {
    1: 'BE',  # Excelente/Bom
    2: 'BN',  # Regular (conservador â€” poderia ser BX)
    3: 'BI',  # Pobre
}

def process_kromp_dataset(images_dir: str):
    """Processa 2.344 blastocistos humanos do dataset Kromp."""
    csv_path = Path(images_dir) / 'annotations_train.csv'
    # Parse CSV: image_id, EXP, ICM, TE
    # Para cada imagem:
    #   1. Enviar pro DINOv2 /analyze-embryo (gera embedding + composite)
    #   2. Mapear Gardner â†’ PassaGene
    #   3. Inserir no Supabase com species='human'
    print(f"Processando Kromp dataset: {images_dir}")
    # ... implementaÃ§Ã£o

def process_rocha_dataset(images_dir: str):
    """Processa 482 blastocistos bovinos do dataset Rocha."""
    # Parse XLS: image_id, grade (mode of 3 embryologists)
    # Para cada imagem:
    #   1. Enviar pro DINOv2 /analyze-embryo
    #   2. Mapear IETS â†’ PassaGene
    #   3. Inserir no Supabase com species='bovine_rocha'
    print(f"Processando Rocha dataset: {images_dir}")
    # ... implementaÃ§Ã£o

def train_mlp_classifier(supabase_url: str, supabase_key: str):
    """Treina MLP com todos os embeddings do atlas cross-species."""
    # 1. Buscar todos os embeddings + classificaÃ§Ãµes do Supabase
    # 2. Split 80/20 stratified
    # 3. Treinar MLP (768 â†’ 256 â†’ 7) por ~50 epochs
    # 4. Salvar pesos em embryo_classifier.pth
    # 5. Upload pro container DINOv2
    print("Treinando classificador MLP cross-species...")
    # ... implementaÃ§Ã£o

if __name__ == '__main__':
    process_kromp_dataset('./datasets/kromp')
    process_rocha_dataset('./datasets/rocha')
    train_mlp_classifier(SUPABASE_URL, SUPABASE_KEY)
    print("Atlas bootstrap completo: ~2.826 referÃªncias cross-species + classificador MLP")
```

### 10.12 Crescimento e transiÃ§Ã£o automÃ¡tica

```
FASE 1 â€” Bootstrap Cross-Species (dia 0)
  Atlas: 2.826 refs (2.344 humanas + 482 bovinas Rocha)
  Scoring: MLP (peso alto) + KNN cross-species (peso baixo)
  PrecisÃ£o estimada: ~55-65% (cross-species nÃ£o Ã© perfeito)
  â–¼

FASE 2 â€” Primeiras semanas (dias 1-14)
  Atlas: 2.826 cross-species + 50-200 bovinas reais
  Scoring: MLP + KNN (dados reais comeÃ§am a ter peso)
  PrecisÃ£o estimada: ~65-75%
  â–¼

FASE 3 â€” Atlas em maturaÃ§Ã£o (mÃªs 1-2)
  Atlas: 2.826 cross-species + 500-1.000 bovinas reais
  Scoring: KNN domina (dados reais tÃªm similaridade maior)
  ReferÃªncias humanas sÃ£o gradualmente "empurradas" no ranking
  PrecisÃ£o estimada: ~75-85%
  â–¼

FASE 4 â€” Atlas maduro (mÃªs 3+)
  Atlas: 2.826 cross-species + 1.500+ bovinas reais
  Scoring: KNN puro (referÃªncias reais dominam completamente)
  MLP vira verificaÃ§Ã£o interna silenciosa
  PrecisÃ£o estimada: ~85-90%
  â–¼

FASE 5 â€” Multi-lab (mÃªs 6+)
  Atlas: cross-species + 3.000+ bovinas reais de mÃºltiplos labs
  KNN puro, cada lab contribui, efeito rede
  PrecisÃ£o estimada: ~90%+
  PossÃ­vel DEPRECAR referÃªncias humanas do KNN (manter sÃ³ pra MLP)
```

**A transiÃ§Ã£o Ã© orgÃ¢nica e automÃ¡tica.** NÃ£o precisa de intervenÃ§Ã£o manual. Os dados bovinos reais naturalmente tÃªm similaridade maior com bovinos novos do que as referÃªncias humanas, entÃ£o o KNN automaticamente prioriza dados reais conforme eles acumulam.

### 10.13 O que NÃƒO fazer

- **NÃƒO** deixar IA generativa classificar direto sem revisÃ£o humana â†’ polui atlas
- **NÃƒO** misturar embeddings de setups muito diferentes sem flag â†’ species obrigatÃ³rio
- **NÃƒO** assumir que cross-species substitui dados reais â†’ Ã© PONTE temporÃ¡ria
- **NÃƒO** deletar referÃªncias cross-species quando atlas matura â†’ mantÃ©m como fallback
- **NÃƒO** adicionar pesos artificiais por espÃ©cie â†’ similaridade natural do DINOv2 jÃ¡ resolve

---

## 11. ESCALA COMERCIAL

### 11.1 Como funciona para novos labs

```
Lab novo assina PassaGene â†’ IA funciona dia 1 (banco central)
â†’ BiÃ³logo despacha normalmente â†’ Cada classificaÃ§Ã£o vira referÃªncia
â†’ Modelo melhora pra TODOS os labs
```

**Nenhuma calibraÃ§Ã£o. Nenhum treinamento. Funciona do primeiro dia.**

### 11.2 Efeito rede

Mais labs â†’ mais referÃªncias â†’ KNN mais preciso â†’ mais labs querem usar. Banco central anonimizado (sem dados do lab na busca KNN).

### 11.3 Moat competitivo

1. **Dados proprietÃ¡rios:** Cada embriÃ£o anotado por biÃ³logo Ã© dado exclusivo
2. **Efeito rede:** Mais labs = mais dados = modelo melhor
3. **IntegraÃ§Ã£o:** Score vive dentro do PassaGene, nÃ£o Ã© produto isolado
4. **Custo zero de IA:** DINOv2 open source, pgvector incluso
5. **Patente:** Sistema integrado (marketplace + IA + gestÃ£o reprodutiva)
6. **Transfer learning cross-species:** Atlas nasce com ~2.800 referÃªncias (dados humanos pÃºblicos). Nenhum concorrente bovino no Brasil estÃ¡ usando dados humanos para bootstrap. Barreira de conhecimento tÃ©cnico alto.
7. **Scoring dual (KNN + MLP):** Classificador treinado em dados cross-species funciona desde o dia 1. Concorrentes que usam sÃ³ IA generativa (Gemini, GPT) alucinam.

---

## 12. EVOLUÃ‡ÃƒO FUTURA â€” PREDIÃ‡ÃƒO DE PRENHEZ

Quando o banco tiver resultados de DG (diagnÃ³stico de gestaÃ§Ã£o):

```
EmbriÃ£o novo â†’ embedding â†’ KNN encontra 10 similares
  â†’ Dos 10: 7 tÃªm DG, 5 prenharam (71%)
  â†’ "EmbriÃµes similares tiveram 71% de taxa de prenhez (7 casos DG)"
```

| Volume com DG | Confiabilidade |
|---|---|
| < 100 | NÃ£o mostrar |
| 100-500 | Indicativo com caveat |
| 500-1.000 | Com confianÃ§a |
| 1.000+ | ConfiÃ¡vel |

**PatenteÃ¡vel e vendÃ¡vel.** Nenhum outro sistema de FIV bovina no Brasil faz isso.

---

## 13. CONFIGURAÃ‡ÃƒO DE GRAVAÃ‡ÃƒO

### Equipamento do lab de referÃªncia

- MicroscÃ³pio: Nikon SMZ 645 (zoom 0.8-5x)
- Adaptador: OptiREC (fÃ­sico)
- Celular: Samsung Galaxy S23
- Lente: Telefoto 10MP (3x Ã³ptico fixo)

### ConfiguraÃ§Ãµes Samsung Video Pro

| ParÃ¢metro | Valor | Motivo |
|---|---|---|
| Lente | T (Telefoto 3x) | Zoom Ã³ptico sem degradaÃ§Ã£o |
| ResoluÃ§Ã£o | FHD 60fps | Captura micro-movimentos |
| ISO | 100 | MÃ­nimo ruÃ­do |
| Shutter | 1/125s | Congela frames sem blur |
| Foco | MF (manual) | Evita ajustes entre frames |
| WB | 2800-4000K manual | Fundo neutro |
| ExposiÃ§Ã£o | Manual travada | Sem mudanÃ§as de brilho |
| EstabilizaÃ§Ã£o | OFF | Evita crop variÃ¡vel |
| HDR | OFF | Processa frames diferente |
| Codec | H.264 | Menos artefatos |
| Alta taxa de bits | ON | Dados mais limpos |

### Requisitos mÃ­nimos para labs clientes

- VÃ­deo â‰¥ 2 segundos (30+ frames)
- EmbriÃ£o focado e visÃ­vel
- IluminaÃ§Ã£o estÃ¡vel
- Sem zoom digital (sÃ³ Ã³ptico)

O DINOv2 Ã© robusto a variaÃ§Ãµes. O sistema de subtraÃ§Ã£o de ruÃ­do compensa tremidos e artefatos.

---

## 14. VARIÃVEIS DE AMBIENTE

Adicionar: `DINOV2_CLOUD_RUN_URL`  
Manter: `CLOUD_RUN_URL`, `GEMINI_API_KEY` (para box_2d)

---

## 15. SPRINTS

| Sprint | Tempo | O que |
|---|---|---|
| 1. Banco | 1 dia | pgvector, tabela (com species/source), funÃ§Ã£o match_embryos, alters, bucket |
| 2. DINOv2 Cloud Run | 1-2 dias | app.py (com endpoint MLP), Dockerfile, deploy com GPU L4 |
| 3. Cloud Run existente | 1 dia | /extract-and-crop, deprecar /analyze-activity |
| 4. Edge Function | 2-3 dias | Reescrever passos, paralelo, KNN, scoring dual, deletar Gemini |
| 5. Frontend | 3-4 dias | ReviewPanel, PlatePanorama, Minimap, ClassButtons, Dashboard, indicadores cross-species |
| 6. Bootstrap cross-species | 1-2 dias | Baixar Kromp (2.344) + Rocha (482), gerar embeddings, mapear classificaÃ§Ãµes, popular atlas |
| 7. Classificador MLP | 1 dia | Treinar MLP com embeddings cross-species, deploy no container DINOv2 |
| 8. Refinamentos | ongoing | Desfazer, dashboard admin, DG, retenÃ§Ã£o vÃ­deos, deprecar refs humanas quando atlas maduro |

---

## 16. CHECKLIST

```
[ ] Cloud Run DINOv2 /health ok
[ ] Cloud Run DINOv2 /analyze-embryo retorna embedding 768d + mlp_classification
[ ] Cloud Run /extract-and-crop retorna crops + plate_frame
[ ] 40 frames NUNCA chegam na Edge Function
[ ] KNN retorna vizinhos por similaridade (ou vazio quando banco vazio)
[ ] KNN com insufficient_data quando < 3 vizinhos bons
[ ] Edge Function: pipeline completo funciona
[ ] Edge Function: DINOv2 chamado em paralelo
[ ] Edge Function: scoring dual (KNN + MLP) com peso dinÃ¢mico
[ ] plate_frame.jpg salvo no Storage por despacho
[ ] PlatePanorama mostra embriÃµes navegÃ¡veis
[ ] EmbryoMinimap mostra posiÃ§Ã£o no card
[ ] Card mostra frame + mapa + sugestÃ£o KNN/MLP combinada
[ ] Indicador fonte: "knn" / "knn_mlp_agree" / "knn_mlp_disagree" / "mlp_only" / "insufficient"
[ ] "Aprendendo..." quando insufficient_data ou mlp_only
[ ] ClassificaÃ§Ã£o salva em embryo_scores + embryo_references (species='bovine_real')
[ ] "Confirmar â†’ prÃ³ximo" avanÃ§a pro pendente
[ ] DispatchSummary aparece quando todos classificados
[ ] Progresso "12/15" atualiza em tempo real
[ ] Atlas bootstrap: Kromp (2.344 humanas) processadas e inseridas com species='human'
[ ] Atlas bootstrap: Rocha (482 bovinas) processadas e inseridas com species='bovine_rocha'
[ ] Classificador MLP treinado com embeddings cross-species e deploy no container
[ ] MLP retorna classificaÃ§Ã£o + confidence + probabilities por classe
[ ] Peso dinÃ¢mico KNNâ†”MLP ajusta automaticamente conforme atlas real cresce
[ ] ReferÃªncias humanas identificadas com species='human' (analytics)
[ ] Gemini avaliaÃ§Ã£o NÃƒO Ã© mais chamado
[ ] /extract-frame antigo ainda funciona
```

---

## 17. MUDANÃ‡AS POR ARQUIVO

| Arquivo | AÃ§Ã£o |
|---|---|
| **BANCO** | |
| Migration SQL | Criar extensÃ£o, tabela (com species/source), funÃ§Ã£o match_embryos, alters |
| **CLOUD RUN NOVO** | |
| `embryoscore-dinov2/app.py` | **Criar** (inclui endpoint MLP + modelo classificador) |
| `embryoscore-dinov2/Dockerfile` | **Criar** |
| `embryoscore-dinov2/embryo_classifier.pth` | **Criar** (pesos MLP treinado cross-species) |
| **CLOUD RUN EXISTENTE** | |
| `/extract-and-crop` | **Adicionar** |
| `/extract-frame` | NÃ£o mexer |
| `/analyze-activity` | Deprecar |
| **EDGE FUNCTION** | |
| `supabase/functions/embryo-analyze/index.ts` | **Reescrever** (scoring dual KNN + MLP) |
| **FRONTEND â€” CRIAR** | |
| `src/components/embryoscore/EmbryoReviewPanel.tsx` | **Criar** |
| `src/components/embryoscore/PlatePanorama.tsx` | **Criar** |
| `src/components/embryoscore/EmbryoMinimap.tsx` | **Criar** |
| `src/components/embryoscore/BiologistClassButtons.tsx` | **Criar** |
| `src/components/embryoscore/DispatchSummary.tsx` | **Criar** |
| **FRONTEND â€” REESCREVER** | |
| `src/components/embryoscore/EmbryoScoreCard.tsx` | **Reescrever** (indicadores cross-species/dual scoring) |
| `src/components/embryoscore/LoteScoreDashboard.tsx` | **Reescrever** |
| **SCRIPTS â€” CRIAR** | |
| `scripts/bootstrap_atlas.py` | **Criar** (download + processamento Kromp/Rocha + popular atlas) |
| `scripts/train_classifier.py` | **Criar** (treinar MLP com embeddings cross-species) |
| **NÃƒO MEXER** | |
| `EmbryoCamera.jsx` | âœ… |
| `useEmbryoVideoUpload.ts` | âœ… |
| `LotesFIV.tsx` | âœ… |
| `LoteDetailView.tsx` | âœ… |
| `VideoUploadButton.tsx` | âœ… |

---

## 18. DESIGN SYSTEM â€” PassaGene DS (OBRIGATÃ“RIO)

### Fontes

```
font-heading: Outfit          â€” tÃ­tulos, H1-H3, nomes de seÃ§Ã£o
font-sans:    Manrope          â€” texto, labels, descriÃ§Ãµes
font-mono:    JetBrains Mono   â€” cÃ³digos de classe, valores, mÃ©tricas
```

### Cores

```
PrimÃ¡rias (verde da marca):
  primary:        #2ECC71  â€” botÃµes, badges ativos, barras votaÃ§Ã£o
  primary-dark:   #1E8449  â€” hover, bordas ativas
  primary-light:  #82E0AA  â€” destaques suaves
  primary-subtle: #D5F5E3  â€” fundo de selecionados, badges

Logo direta:
  passagene.primary: #09C972, primary-dark: #049357, primary-light: #5EDFA3

SemÃ¢nticas:
  destructive:    #EF4444  â€” erros, alertas, "Degenerado"
  accent:         #27AE60  â€” alternativa ao primary

Neutros: background, card, foreground, muted, muted-foreground, border, secondary (CSS vars)
```

### Border Radius

```
rounded-sm: 4px   rounded: 8px (default)   rounded-lg: 12px
rounded-2xl: 20px   rounded-full: pill
```

### Sombras (tom verde sutil)

```
shadow-sm:  0 1px 3px rgba(9,201,114,0.08)
shadow:     0 4px 12px rgba(9,201,114,0.12)
shadow-lg:  0 8px 24px rgba(4,147,87,0.15)
```

### Componentes shadcn/ui

Card, Button (default/outline/ghost/destructive), Input, Label, Table, Badge

### Ãcones: lucide-react

Check, X, Eye, Camera, Upload, ChevronRight, Undo2

### PadrÃµes de aplicaÃ§Ã£o EmbryoScore

```tsx
// Card principal
<Card className="rounded-2xl border-border shadow-sm">

// CÃ³digo classe
<span className="font-mono text-2xl font-bold text-primary">BN</span>

// MÃ©trica
<div className="bg-muted rounded-lg p-3 text-center">
  <span className="font-mono text-lg font-semibold">{value}%</span>
  <span className="text-xs text-muted-foreground block mt-1">Intensidade</span>
</div>

// BotÃ£o classe normal
<Button variant="outline" className="rounded-lg p-3 h-auto flex-col">

// BotÃ£o classe selecionado
<Button variant="outline" className="rounded-lg p-3 h-auto flex-col border-primary bg-primary-subtle">

// BotÃ£o classe sugestÃ£o IA
<Button variant="outline" className="rounded-lg p-3 h-auto flex-col ring-1 ring-primary/20">

// Barra votaÃ§Ã£o
<div className="h-5 bg-muted rounded-sm overflow-hidden">
  <div className="h-full bg-primary rounded-sm" style={{ width: `${pct}%` }} />
</div>

// Badge status
<span className="inline-flex items-center px-2 py-1 rounded-full text-xs font-medium bg-primary-subtle text-primary-dark">

// Aprendendo
<div className="text-center py-4 text-muted-foreground text-sm">
  ğŸ” Aprendendo... Classifique manualmente ({refCount} referÃªncias)
</div>

// Dark mode: automÃ¡tico via CSS variables
```

---

## 19. DECISÃ•ES TÃ‰CNICAS â€” RESUMO

| DecisÃ£o | Escolha | Descartado | Motivo |
|---|---|---|---|
| AvaliaÃ§Ã£o | DINOv2 + KNN + MLP | Gemini/Claude direto | IA generativa alucina |
| Modelo visual | DINOv2 ViT-B/14 | CLIP, ResNet | Melhor similaridade visual |
| CinÃ©tica | Diff pixels + subtraÃ§Ã£o ruÃ­do | MÃ©tricas separadas | Preserva info espacial |
| CombinaÃ§Ã£o | Imagem composta | Vetor concatenado | Um processamento sÃ³ |
| Processamento | Server-side Cloud Run | Browser JS | NÃ£o trava celular |
| GPU | Google Cloud Run L4 | Modal, Replicate | Mesmo ecossistema |
| Recorte | ServiÃ§o existente Gemini | OpenCV browser | JÃ¡ funciona, nÃ£o mexer |
| Busca vetorial | Supabase pgvector | Pinecone, Weaviate | JÃ¡ usa Supabase |
| Treinamento DINOv2 | Nenhum (out-of-box) | Fine-tune | Funciona sem dados |
| Classificador | MLP treinado cross-species | Nenhum classificador | Funciona desde dia 1, custo zero |
| Bootstrap | Cross-species (humano+bovino) | 35 embriÃµes manuais | 2.826 refs vs 35, IA funciona dia 1 |
| Peso cross-species | Nenhum (similaridade natural) | Peso artificial por espÃ©cie | DINOv2 jÃ¡ prioriza setup similar |
| Scoring | Dual (KNN + MLP) com peso dinÃ¢mico | KNN sozinho | MLP cobre quando KNN insuficiente |
| Melhoria | KNN banco crescente + MLP fixo | Retreino periÃ³dico | Sem retreino, transiÃ§Ã£o orgÃ¢nica |
| Frames | Nunca saem do Cloud Run | Edge Function manipula | MemÃ³ria insuficiente |
| Fallback IA generativa | Opcional (prompt rico) | ObrigatÃ³rio | Custo alto, sÃ³ se MLP+KNN falham |

---

## 20. OTIMIZAÃ‡Ã•ES INCORPORADAS

| OtimizaÃ§Ã£o | Onde |
|---|---|
| 40 frames nunca saem do Cloud Run | SeÃ§Ã£o 6b, /extract-and-crop |
| ParalelizaÃ§Ã£o DINOv2 + KNN | SeÃ§Ã£o 7, Promise.all |
| Threshold mÃ­nimo KNN | SeÃ§Ã£o 7, MIN_SIMILARITY=0.65 |
| Indicador "Aprendendo..." | SeÃ§Ã£o 8d |
| Alinhamento de crops | SeÃ§Ã£o 5.5, align_crops() |
| Placa panorÃ¢mica navegÃ¡vel | SeÃ§Ã£o 8b |
| Minimapa no card | SeÃ§Ã£o 8c |
| ProteÃ§Ã£o contra erro | SeÃ§Ã£o 4b (review_mode) + Sprint 8 (desfazer) |
| Fluxo revisÃ£o prÃ©-despacho | SeÃ§Ã£o 8a |
| Resumo de despacho | SeÃ§Ã£o 8g |
| Atlas cross-species bootstrap | SeÃ§Ã£o 10.5, 2.826 refs dia 0 |
| Similaridade natural prioriza dados reais | SeÃ§Ã£o 4c, sem peso artificial |
| Scoring dual KNN + MLP | SeÃ§Ã£o 10.8-10.9, peso dinÃ¢mico |
| TransiÃ§Ã£o orgÃ¢nica crossâ†’real | SeÃ§Ã£o 10.13, sem intervenÃ§Ã£o manual |
| MLP classificador no mesmo container | SeÃ§Ã£o 10.9, custo zero adicional |

---

## 21. REFERÃŠNCIAS

### Tecnologia
- DINOv2: https://github.com/facebookresearch/dinov2
- pgvector: https://github.com/pgvector/pgvector
- Cloud Run GPU: https://cloud.google.com/run/docs/configuring/services/gpu
- Supabase Vector: https://supabase.com/docs/guides/ai/vector-columns

### Datasets pÃºblicos (Bootstrap Cross-Species)
- Kromp et al. 2023 â€” 2.344 blastocistos humanos com Gardner: https://doi.org/10.6084/m9.figshare.20123153.v3
- Rocha et al. 2017 â€” 482 blastocistos bovinos com IETS: https://doi.org/10.6084/m9.figshare.c.3825241
- Paper Kromp (Scientific Data): https://www.nature.com/articles/s41597-023-02182-3
- Paper Rocha (Scientific Reports): https://www.nature.com/articles/s41598-017-08104-9
- Paper Rocha (Scientific Data): https://www.nature.com/articles/sdata2017192

### Base cientÃ­fica cross-species
- PrincÃ­pios comuns de auto-organizaÃ§Ã£o embrionÃ¡ria mamÃ­fera (Development 2020): https://journals.biologists.com/dev/article/147/14/dev183079
- Blastocistos bovinos derivados de stem cells vs IVF (Cell Stem Cell 2023): https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(23)00121-2
- Review: imaging e spectroscopia para gradaÃ§Ã£o de embriÃµes bovinos (Frontiers Vet Sci 2024): https://www.frontiersin.org/journals/veterinary-science/articles/10.3389/fvets.2024.1364570
- STORK â€” DNN com 50K imagens humanas, AUC >0.98 (npj Digital Medicine 2019): https://www.nature.com/articles/s41746-019-0096-y
- Vitrolife â€” 780K imagens, grading automÃ¡tico ICM/TE: https://blog.vitrolife.com/togetheralltheway/new-publication-automatic-grading-of-human-blastocysts-from-time-lapse-imaging
- ML para avaliaÃ§Ã£o bovina em campo com vÃ­deo celular (J IVF-Worldwide 2025): https://jivfww.scholasticahq.com/article/141131
- Blasto3Q â€” classificaÃ§Ã£o bovina via smartphone (Sensors 2018): https://mdpi.com/1424-8220/18/12/4440

### CitaÃ§Ã£o-chave para abordagem cross-species
> "As first step, the successful approaches and tools in human study should be investigated
> for bovine embryos with appropriate modifications."
> â€” Frontiers in Veterinary Science, 2024 (Review: Application of imaging and spectroscopy
> techniques for grading of bovine embryos)

---

*Documento Ãºnico de referÃªncia para Claude Code. Ordem: banco â†’ DINOv2 (com MLP) â†’ Cloud Run â†’ Edge Function (scoring dual) â†’ Frontend â†’ Bootstrap cross-species â†’ MLP training â†’ Refinamentos. Todos os componentes seguem PassaGene DS.*
